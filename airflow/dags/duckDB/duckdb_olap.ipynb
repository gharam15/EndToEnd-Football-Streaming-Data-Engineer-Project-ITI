{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "04d093e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20c9ae80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file path: C:/Users/ahmed/Downloads/TheSportsDB/airflow/dags/data/kafka_invalid/2025-08-11.parquet\n",
      "File exists? True\n",
      "                   topic                  event_time  \\\n",
      "0  rejected.soccer.event  2025-08-11T16:51:35.238307   \n",
      "1  rejected.soccer.event  2025-08-11T16:51:35.238405   \n",
      "2  rejected.soccer.event  2025-08-11T16:51:35.238427   \n",
      "3  rejected.soccer.event  2025-08-11T16:51:35.238437   \n",
      "4  rejected.soccer.event  2025-08-11T16:51:35.238451   \n",
      "5  rejected.soccer.event  2025-08-11T16:51:35.238463   \n",
      "6  rejected.soccer.event  2025-08-11T16:51:35.238475   \n",
      "7  rejected.soccer.event  2025-08-11T16:51:35.238487   \n",
      "8  rejected.soccer.event  2025-08-11T16:51:35.238494   \n",
      "9  rejected.soccer.event  2025-08-11T16:51:35.238505   \n",
      "\n",
      "                                             message  \n",
      "0  {\"idEvent\":\"2267100\",\"idLeague\":\"4328\",\"idHome...  \n",
      "1  {\"idEvent\":\"2267210\",\"idLeague\":\"4328\",\"idHome...  \n",
      "2  {\"idEvent\":\"2267231\",\"idLeague\":\"4328\",\"idHome...  \n",
      "3  {\"idEvent\":\"2267162\",\"idLeague\":\"4328\",\"idHome...  \n",
      "4  {\"idEvent\":\"2267155\",\"idLeague\":\"4328\",\"idHome...  \n",
      "5  {\"idEvent\":\"2267217\",\"idLeague\":\"4328\",\"idHome...  \n",
      "6  {\"idEvent\":\"2267096\",\"idLeague\":\"4328\",\"idHome...  \n",
      "7  {\"idEvent\":\"2267105\",\"idLeague\":\"4328\",\"idHome...  \n",
      "8  {\"idEvent\":\"2267211\",\"idLeague\":\"4328\",\"idHome...  \n",
      "9  {\"idEvent\":\"2267143\",\"idLeague\":\"4328\",\"idHome...  \n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = Path(r\"C:\\Users\\ahmed\\Downloads\\TheSportsDB\\airflow\\dags\\data\\kafka_invalid\") \n",
    "\n",
    "date_str = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "parquet_file = OUTPUT_DIR / f\"{date_str}.parquet\"\n",
    "\n",
    "con = duckdb.connect(database=':memory:')\n",
    "\n",
    "parquet_file_unix = parquet_file.as_posix()\n",
    "\n",
    "print(\"Checking file path:\", parquet_file_unix)\n",
    "print(\"File exists?\", parquet_file.exists())\n",
    "\n",
    "if parquet_file.exists():\n",
    "    df_preview = con.execute(f\"SELECT * FROM '{parquet_file_unix}' LIMIT 10\").fetchdf()\n",
    "    print(df_preview)\n",
    "else:\n",
    "    print(\"File not found! Please check the path and today_parquet_file on it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "556861bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Count of invalid topics (زي ما هو لكن وسعت العمود ليشمل أكتر من كلمة مفتاحية)\n",
    "query_1 = f\"\"\"\n",
    "SELECT topic, COUNT(*) AS message_count\n",
    "FROM read_parquet('{parquet_file_unix}')\n",
    "GROUP BY topic\n",
    "ORDER BY message_count DESC\n",
    "\"\"\"\n",
    "\n",
    "# 2) Number of messages by hour (time grouping)\n",
    "query_2 = f\"\"\"\n",
    "SELECT\n",
    "  STRFTIME(CAST(event_time AS TIMESTAMP), '%Y-%m-%d %H:00:00') AS hour,\n",
    "  COUNT(*) AS messages_count\n",
    "FROM read_parquet('{parquet_file_unix}')\n",
    "GROUP BY hour\n",
    "ORDER BY hour\n",
    "\"\"\"\n",
    "\n",
    "# 3) Analyze keywords in the message column (زودت keywords)\n",
    "query_3 = f\"\"\"\n",
    "SELECT\n",
    "  topic,\n",
    "  COUNT(*) AS total,\n",
    "  SUM(CASE WHEN LOWER(message) LIKE '%error%' THEN 1 ELSE 0 END) AS error_count,\n",
    "  SUM(CASE WHEN LOWER(message) LIKE '%invalid%' THEN 1 ELSE 0 END) AS invalid_count,\n",
    "  SUM(CASE WHEN LOWER(message) LIKE '%missing%' THEN 1 ELSE 0 END) AS missing_count,\n",
    "  SUM(CASE WHEN LOWER(message) LIKE '%timeout%' THEN 1 ELSE 0 END) AS timeout_count,\n",
    "  SUM(CASE WHEN LOWER(message) LIKE '%failed%' THEN 1 ELSE 0 END) AS failed_count\n",
    "FROM read_parquet('{parquet_file_unix}')\n",
    "GROUP BY topic\n",
    "ORDER BY total DESC\n",
    "\"\"\"\n",
    "\n",
    "# 4) Daily analysis of invalid messages by topic with avg message length\n",
    "query_4 = f\"\"\"\n",
    "SELECT\n",
    "  topic,\n",
    "  DATE(event_time) AS event_date,\n",
    "  COUNT(*) AS invalid_count,\n",
    "  AVG(LENGTH(message)) AS avg_message_length\n",
    "FROM read_parquet('{parquet_file_unix}')\n",
    "WHERE LOWER(message) LIKE '%invalid%'\n",
    "GROUP BY topic, event_date\n",
    "ORDER BY event_date, invalid_count DESC\n",
    "\"\"\"\n",
    "\n",
    "# 5) Percentage of invalid messages by topic\n",
    "query_5 = f\"\"\"\n",
    "WITH total_msgs AS (\n",
    "  SELECT topic, COUNT(*) AS total_count\n",
    "  FROM read_parquet('{parquet_file_unix}')\n",
    "  GROUP BY topic\n",
    "),\n",
    "invalid_msgs AS (\n",
    "  SELECT topic, COUNT(*) AS invalid_count\n",
    "  FROM read_parquet('{parquet_file_unix}')\n",
    "  WHERE LOWER(message) LIKE '%invalid%'\n",
    "  GROUP BY topic\n",
    ")\n",
    "SELECT\n",
    "  t.topic,\n",
    "  t.total_count,\n",
    "  COALESCE(i.invalid_count, 0) AS invalid_count,\n",
    "  ROUND(COALESCE(i.invalid_count, 0) * 100.0 / t.total_count, 2) AS invalid_percentage\n",
    "FROM total_msgs t\n",
    "LEFT JOIN invalid_msgs i ON t.topic = i.topic\n",
    "ORDER BY invalid_percentage DESC\n",
    "\"\"\"\n",
    "\n",
    "# 6) Track daily change in percentage of invalid messages (Trend)\n",
    "query_6 = f\"\"\"\n",
    "WITH daily_stats AS (\n",
    "  SELECT\n",
    "    DATE(event_time) AS event_date,\n",
    "    COUNT(*) AS total_count,\n",
    "    SUM(CASE WHEN LOWER(message) LIKE '%invalid%' THEN 1 ELSE 0 END) AS invalid_count\n",
    "  FROM read_parquet('{parquet_file_unix}')\n",
    "  GROUP BY event_date\n",
    ")\n",
    "SELECT\n",
    "  event_date,\n",
    "  total_count,\n",
    "  invalid_count,\n",
    "  ROUND(invalid_count * 100.0 / total_count, 2) AS invalid_percentage\n",
    "FROM daily_stats\n",
    "ORDER BY event_date\n",
    "\"\"\"\n",
    "\n",
    "# 7) Top 10 frequent messages by topic (غيرت الفلتر عشان يجيب أكتر رسائل شائعة مش بس soccer)\n",
    "query_7 = f\"\"\"\n",
    "SELECT topic, message, COUNT(*) AS occurrences\n",
    "FROM read_parquet('{parquet_file_unix}')\n",
    "GROUP BY topic, message\n",
    "ORDER BY occurrences DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "# 8) Future events (events بعد اليوم)\n",
    "query_8 = f\"\"\"\n",
    "SELECT *\n",
    "FROM read_parquet('{parquet_file_unix}')\n",
    "WHERE CAST(event_time AS DATE) > CURRENT_DATE\n",
    "\"\"\"\n",
    "\n",
    "# 9) Error reason distribution over time (للـ stacked bar chart في Grafana)\n",
    "query_9 = f\"\"\"\n",
    "SELECT\n",
    "  topic,\n",
    "  DATE_TRUNC('hour', CAST(event_time AS TIMESTAMP)) AS hour,\n",
    "  CASE\n",
    "    WHEN LOWER(message) LIKE '%invalid%' THEN 'Invalid'\n",
    "    WHEN LOWER(message) LIKE '%error%' THEN 'Error'\n",
    "    WHEN LOWER(message) LIKE '%missing%' THEN 'Missing'\n",
    "    WHEN LOWER(message) LIKE '%timeout%' THEN 'Timeout'\n",
    "    WHEN LOWER(message) LIKE '%failed%' THEN 'Failed'\n",
    "    ELSE 'Other'\n",
    "  END AS error_category,\n",
    "  COUNT(*) AS count\n",
    "FROM read_parquet('{parquet_file_unix}')\n",
    "GROUP BY topic, hour, error_category\n",
    "ORDER BY hour, topic\n",
    "\"\"\"\n",
    "\n",
    "# 10) Moving average of invalid percentage per topic (trend smoothing)\n",
    "query_10 = f\"\"\"\n",
    "WITH hourly_stats AS (\n",
    "  SELECT\n",
    "    topic,\n",
    "    DATE_TRUNC('hour', CAST(event_time AS TIMESTAMP)) AS hour,\n",
    "    COUNT(*) AS total_count,\n",
    "    SUM(CASE WHEN LOWER(message) LIKE '%invalid%' THEN 1 ELSE 0 END) AS invalid_count\n",
    "  FROM read_parquet('{parquet_file_unix}')\n",
    "  GROUP BY topic, hour\n",
    ")\n",
    "SELECT\n",
    "  topic,\n",
    "  hour,\n",
    "  ROUND(100.0 * invalid_count / total_count, 2) AS invalid_percentage,\n",
    "  AVG(ROUND(100.0 * invalid_count / total_count, 2)) OVER (\n",
    "    PARTITION BY topic\n",
    "    ORDER BY hour\n",
    "    ROWS BETWEEN 5 PRECEDING AND CURRENT ROW\n",
    "  ) AS moving_avg_6_hours\n",
    "FROM hourly_stats\n",
    "ORDER BY topic, hour\n",
    "\"\"\"\n",
    "\n",
    "# 11) Null ratio per row (percentage of nulls in each row)\n",
    "query_11 = f\"\"\"\n",
    "SELECT \n",
    "    topic,\n",
    "    COUNT(*) AS total,\n",
    "    SUM(CASE WHEN message IS NULL THEN 1 ELSE 0 END) AS null_count,\n",
    "    ROUND(SUM(CASE WHEN message IS NULL THEN 1 ELSE 0 END) * 100.0 / COUNT(*), 2) AS null_percentage\n",
    "FROM read_parquet('{parquet_file_unix}')\n",
    "GROUP BY topic\n",
    "ORDER BY null_percentage DESC;\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# 12) This query calculates the percentage of null values in each row for the specified columns.\n",
    "query_12 = f\"\"\"\n",
    "SELECT \n",
    "    *,\n",
    "    ROUND(\n",
    "        (\n",
    "            (CASE WHEN topic IS NULL THEN 1 ELSE 0 END) +\n",
    "            (CASE WHEN event_time IS NULL THEN 1 ELSE 0 END) +\n",
    "            (CASE WHEN message IS NULL THEN 1 ELSE 0 END)\n",
    "        ) * 100.0 / 3, \n",
    "        2\n",
    "    ) AS null_percentage_per_row\n",
    "FROM read_parquet('{parquet_file_unix}');\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e67b7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_topic_counts              = con.execute(query_1).fetchdf()\n",
    "df_hourly_counts             = con.execute(query_2).fetchdf()\n",
    "df_keyword_analysis          = con.execute(query_3).fetchdf()\n",
    "df_daily_invalid             = con.execute(query_4).fetchdf()\n",
    "df_invalid_percentage_per_topic = con.execute(query_5).fetchdf()\n",
    "df_daily_invalid_trend       = con.execute(query_6).fetchdf()\n",
    "df_top_invalid_messages      = con.execute(query_7).fetchdf()\n",
    "df_future_events             = con.execute(query_8).fetchdf()\n",
    "df_rejected_reasons          = con.execute(query_9).fetchdf()\n",
    "df_moving_avg_invalid        = con.execute(query_10).fetchdf()\n",
    "df_percentage_nulls_each_row = con.execute(query_11).fetchdf()\n",
    "df_specified_col_null_per    = con.execute(query_12).fetchdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f421d4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) Messages count by topic:\n",
      "                              topic  message_count\n",
      "0             rejected.soccer.event          16321\n",
      "1             rejected.soccer.venue             86\n",
      "2  rejected.soccer.event.highlights             10\n"
     ]
    }
   ],
   "source": [
    "print(\"1) Messages count by topic:\")\n",
    "print(df_topic_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "45092d0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2) Messages count by hour:\n",
      "                  hour  messages_count\n",
      "0  2025-08-11 16:00:00           16417\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n2) Messages count by hour:\")\n",
    "print(df_hourly_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1af8d0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3) Keyword analysis by topic:\n",
      "                              topic  total  error_count  invalid_count  \\\n",
      "0             rejected.soccer.event  16321          1.0            0.0   \n",
      "1             rejected.soccer.venue     86          0.0            0.0   \n",
      "2  rejected.soccer.event.highlights     10          0.0            0.0   \n",
      "\n",
      "   missing_count  timeout_count  failed_count  \n",
      "0            0.0            0.0           0.0  \n",
      "1            0.0            0.0           0.0  \n",
      "2            0.0            0.0           0.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n3) Keyword analysis by topic:\")\n",
    "print(df_keyword_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1741481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "4) Daily invalid messages with average message length:\n",
      "Empty DataFrame\n",
      "Columns: [topic, event_date, invalid_count, avg_message_length]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n4) Daily invalid messages with average message length:\")\n",
    "print(df_daily_invalid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2057ac13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5) Percentage of invalid messages by topic:\n",
      "                              topic  total_count  invalid_count  \\\n",
      "0  rejected.soccer.event.highlights           10              0   \n",
      "1             rejected.soccer.venue           86              0   \n",
      "2             rejected.soccer.event        16321              0   \n",
      "\n",
      "   invalid_percentage  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n5) Percentage of invalid messages by topic:\")\n",
    "print(df_invalid_percentage_per_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d787d602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6) Daily invalid percentage trend:\n",
      "  event_date  total_count  invalid_count  invalid_percentage\n",
      "0 2025-08-11        16417            0.0                 0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n6) Daily invalid percentage trend:\")\n",
    "print(df_daily_invalid_trend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e8c64c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "7) Top 10 frequent messages by topic:\n",
      "                   topic                                            message  \\\n",
      "0  rejected.soccer.venue  {\"idVenue\":\"21398\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "1  rejected.soccer.venue  {\"idVenue\":\"24006\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "2  rejected.soccer.venue  {\"idVenue\":\"24006\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "3  rejected.soccer.venue  {\"idVenue\":\"16479\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "4  rejected.soccer.venue  {\"idVenue\":\"16479\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "5  rejected.soccer.venue  {\"idVenue\":\"17728\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "6  rejected.soccer.venue  {\"idVenue\":\"17728\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "7  rejected.soccer.venue  {\"idVenue\":\"21398\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "8  rejected.soccer.venue  {\"idVenue\":\"17728\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "9  rejected.soccer.venue  {\"idVenue\":\"17728\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "\n",
      "   occurrences  \n",
      "0            2  \n",
      "1            2  \n",
      "2            2  \n",
      "3            2  \n",
      "4            2  \n",
      "5            2  \n",
      "6            2  \n",
      "7            2  \n",
      "8            2  \n",
      "9            2  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n7) Top 10 frequent messages by topic:\")\n",
    "print(df_top_invalid_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d6e23c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "8) Future events after today:\n",
      "Empty DataFrame\n",
      "Columns: [topic, event_time, message]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n8) Future events after today:\")\n",
    "print(df_future_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ac36f7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9) Error reason distribution over time:\n",
      "                              topic                hour error_category  count\n",
      "0             rejected.soccer.event 2025-08-11 16:00:00          Other  16320\n",
      "1             rejected.soccer.event 2025-08-11 16:00:00          Error      1\n",
      "2  rejected.soccer.event.highlights 2025-08-11 16:00:00          Other     10\n",
      "3             rejected.soccer.venue 2025-08-11 16:00:00          Other     86\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n9) Error reason distribution over time:\")\n",
    "print(df_rejected_reasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8ef55fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10) Moving average of invalid percentage per topic:\n",
      "                              topic                hour  invalid_percentage  \\\n",
      "0             rejected.soccer.event 2025-08-11 16:00:00                 0.0   \n",
      "1  rejected.soccer.event.highlights 2025-08-11 16:00:00                 0.0   \n",
      "2             rejected.soccer.venue 2025-08-11 16:00:00                 0.0   \n",
      "\n",
      "   moving_avg_6_hours  \n",
      "0                 0.0  \n",
      "1                 0.0  \n",
      "2                 0.0  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\n10) Moving average of invalid percentage per topic:\")\n",
    "print(df_moving_avg_invalid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "fe14975d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "11) Null ratio per row (percentage of nulls in each row:\n",
      "                              topic  total  null_count  null_percentage\n",
      "0  rejected.soccer.event.highlights     10         0.0              0.0\n",
      "1             rejected.soccer.venue     86         0.0              0.0\n",
      "2             rejected.soccer.event  16321         0.0              0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n11) Null ratio per row (percentage of nulls in each row:\")\n",
    "print(df_percentage_nulls_each_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4f3faaa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "12)  This query calculates the percentage of null values in each row for the specified columns:\n",
      "                       topic                  event_time  \\\n",
      "0      rejected.soccer.event  2025-08-11T16:51:35.238307   \n",
      "1      rejected.soccer.event  2025-08-11T16:51:35.238405   \n",
      "2      rejected.soccer.event  2025-08-11T16:51:35.238427   \n",
      "3      rejected.soccer.event  2025-08-11T16:51:35.238437   \n",
      "4      rejected.soccer.event  2025-08-11T16:51:35.238451   \n",
      "...                      ...                         ...   \n",
      "16412  rejected.soccer.venue  2025-08-11T16:53:04.007535   \n",
      "16413  rejected.soccer.venue  2025-08-11T16:53:04.007549   \n",
      "16414  rejected.soccer.venue  2025-08-11T16:53:04.007564   \n",
      "16415  rejected.soccer.venue  2025-08-11T16:53:04.007577   \n",
      "16416  rejected.soccer.venue  2025-08-11T16:53:04.007661   \n",
      "\n",
      "                                                 message  \\\n",
      "0      {\"idEvent\":\"2267100\",\"idLeague\":\"4328\",\"idHome...   \n",
      "1      {\"idEvent\":\"2267210\",\"idLeague\":\"4328\",\"idHome...   \n",
      "2      {\"idEvent\":\"2267231\",\"idLeague\":\"4328\",\"idHome...   \n",
      "3      {\"idEvent\":\"2267162\",\"idLeague\":\"4328\",\"idHome...   \n",
      "4      {\"idEvent\":\"2267155\",\"idLeague\":\"4328\",\"idHome...   \n",
      "...                                                  ...   \n",
      "16412  {\"idVenue\":\"21427\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "16413  {\"idVenue\":\"24006\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "16414  {\"idVenue\":\"21391\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "16415  {\"idVenue\":\"21396\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "16416  {\"idVenue\":\"24520\",\"intFormedYear\":\"0\",\"strVen...   \n",
      "\n",
      "       null_percentage_per_row  \n",
      "0                          0.0  \n",
      "1                          0.0  \n",
      "2                          0.0  \n",
      "3                          0.0  \n",
      "4                          0.0  \n",
      "...                        ...  \n",
      "16412                      0.0  \n",
      "16413                      0.0  \n",
      "16414                      0.0  \n",
      "16415                      0.0  \n",
      "16416                      0.0  \n",
      "\n",
      "[16417 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n12)  This query calculates the percentage of null values in each row for the specified columns:\")\n",
    "print(df_specified_col_null_per)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "9c3f2b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       topic                  event_time  total_keys  \\\n",
      "1737   rejected.soccer.event  2025-08-11T16:51:36.103012          33   \n",
      "741    rejected.soccer.event  2025-08-11T16:51:35.510355          33   \n",
      "1558   rejected.soccer.event  2025-08-11T16:51:36.100157          33   \n",
      "2834   rejected.soccer.event  2025-08-11T16:51:36.597986          33   \n",
      "2485   rejected.soccer.event  2025-08-11T16:51:36.398428          33   \n",
      "...                      ...                         ...         ...   \n",
      "16289  rejected.soccer.event  2025-08-11T16:52:39.145877          22   \n",
      "16290  rejected.soccer.event  2025-08-11T16:52:39.145889          22   \n",
      "16291  rejected.soccer.event  2025-08-11T16:52:39.145902          22   \n",
      "16292  rejected.soccer.event  2025-08-11T16:52:39.145994          22   \n",
      "16293  rejected.soccer.event  2025-08-11T16:52:39.146017          22   \n",
      "\n",
      "       null_keys  null_percentage  \n",
      "1737          11            33.33  \n",
      "741           11            33.33  \n",
      "1558          11            33.33  \n",
      "2834          11            33.33  \n",
      "2485          11            33.33  \n",
      "...          ...              ...  \n",
      "16289          0             0.00  \n",
      "16290          0             0.00  \n",
      "16291          0             0.00  \n",
      "16292          0             0.00  \n",
      "16293          0             0.00  \n",
      "\n",
      "[16417 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# This function converts nested JSON structures into a flat dictionary and calculates null percentages for every key and value in msg  \n",
    "def flatten_json(y):\n",
    "    \"\"\"change to flatten JSON form nested\"\"\"\n",
    "    out = {}\n",
    "    def flatten(x, name=''):\n",
    "        if isinstance(x, dict):\n",
    "            for a in x:\n",
    "                flatten(x[a], f\"{name}{a}.\")\n",
    "        elif isinstance(x, list):\n",
    "            for i, a in enumerate(x):\n",
    "                flatten(a, f\"{name}{i}.\")\n",
    "        else:\n",
    "            out[name[:-1]] = x\n",
    "    flatten(y)\n",
    "    return out\n",
    "\n",
    "results = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    try:\n",
    "        msg_dict = json.loads(row['message'])\n",
    "    except Exception:\n",
    "        continue\n",
    "    \n",
    "    flat_msg = flatten_json(msg_dict)\n",
    "    total_keys = len(flat_msg)\n",
    "    null_keys = sum(1 for v in flat_msg.values() if v is None or v == \"\" or str(v).lower() == \"null\")\n",
    "    null_percentage = round((null_keys / total_keys) * 100, 2) if total_keys else 0\n",
    "\n",
    "    results.append({\n",
    "        \"topic\": row['topic'],\n",
    "        \"event_time\": row['event_time'],\n",
    "        \"total_keys\": total_keys,\n",
    "        \"null_keys\": null_keys,\n",
    "        \"null_percentage\": null_percentage\n",
    "    })\n",
    "\n",
    "import pandas as pd\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(\"null_percentage\", ascending=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
